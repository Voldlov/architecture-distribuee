{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructType, StructField, TimestampType, DoubleType, ArrayType\n",
    "from pyspark.sql.functions import from_json, udf, col, array_contains, split, count\n",
    "from pyspark.sql import functions as F\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from tools import get_list_of_keys\n",
    "\n",
    "CURRENCIES = get_list_of_keys('symbol')\n",
    "\n",
    "load_dotenv()\n",
    "MONGODB_ATLAS_USER = os.getenv(\"MONGODB_ATLAS_USER\")\n",
    "MONGODB_ATLAS_PASSWORD = os.getenv(\"MONGODB_ATLAS_PASSWORD\")\n",
    "MONGODB_ATLAS_URI = \"mongodb+srv://{}:{}@cluster0.6jprsq1.mongodb.net/\".format(MONGODB_ATLAS_USER, MONGODB_ATLAS_PASSWORD)\n",
    "MONGO_DB_NAME = os.getenv(\"MONGODB_ATLAS_DATABASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se connecter à la base de donnée mongoDB\n",
    "pymongo_client = MongoClient(MONGODB_ATLAS_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancement Spark session\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName(\"pyspark-notebook\"). \\\n",
    "    master(\"spark://spark-master:7077\"). \\\n",
    "    config(\"spark.executor.memory\", \"2g\"). \\\n",
    "    config(\"spark.mongodb.input.uri\", MONGODB_ATLAS_URI). \\\n",
    "    config(\"spark.mongodb.output.uri\", MONGODB_ATLAS_URI). \\\n",
    "    config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def load_df_from_kafka(spark_s, topic):\n",
    "    return spark_s \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_hashtags(tweet: str) -> list:\n",
    "    hashtags = re.findall('([#][a-zA-Z]+)', str(tweet))\n",
    "    return [item for item in CURRENCIES if '#{}'.format(item) in (tag.lower() for tag in hashtags)]\n",
    "\n",
    "\n",
    "tweet_stream_df = load_df_from_kafka(spark, \"tweeting\")\n",
    "tweet_schema = StructType([StructField(\"text\", StringType(), True), StructField('date', TimestampType(), True)])\n",
    "tweets_values = tweet_stream_df.select(from_json(tweet_stream_df.value.cast(\"string\"), tweet_schema).alias(\"tweet\"))\n",
    "\n",
    "df1 = tweets_values.select(\"tweet.*\")\n",
    "clean_tweets = F.udf(get_matching_hashtags, StringType())\n",
    "raw_tweets = df1.withColumn('cryptos', clean_tweets(col(\"text\")))\n",
    "\n",
    "def write_row_in_tweet_mongo(df, id):\n",
    "    df.write.format(\"mongo\").mode(\"append\").option(\"uri\", MONGODB_ATLAS_URI + \"development.tweets\" + \"?retryWrites=true&w=majority\").save()\n",
    "    pass\n",
    "\n",
    "raw_tweets \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(write_row_in_tweet_mongo) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_stream_df = load_df_from_kafka(spark, \"crypto\")\n",
    "crypto_schema = StructType([StructField(\"name\", StringType(), True), StructField(\"symbol\", StringType(), True), StructField(\"value\", DoubleType(), True), StructField('date', TimestampType(), True)])\n",
    "crypto_values = crypto_stream_df.select(from_json(crypto_stream_df.value.cast(\"string\"), crypto_schema).alias(\"crypto\"))\n",
    "df_crypto = crypto_values.select(\"crypto.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_row_in_crypto_mongo(df, id):\n",
    "    df.write.format(\"mongo\").mode(\"append\").option(\"uri\", MONGODB_ATLAS_URI + \"development.cryptos\" + \"?retryWrites=true&w=majority\").save()\n",
    "    pass\n",
    "\n",
    "df_crypto \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(write_row_in_crypto_mongo) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(df_to_treat, db, crypto):\n",
    "    data = {\n",
    "        \"nbr_tweets\": df_to_treat.count(),\n",
    "        \"crypto_name\": crypto,\n",
    "        \"datetime\": datetime.now() + timedelta(hours=1)\n",
    "    }\n",
    "    db['results'].insert_one(data)\n",
    "\n",
    "@udf(returnType = ArrayType(StringType()))\n",
    "def clean_crypto_array(value):\n",
    "    return value.strip('[]').split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo_client[MONGO_DB_NAME]\n",
    "\n",
    "time_between_treatment = 900\n",
    "while True:\n",
    "    db[\"tweets\"].drop()\n",
    "    time.sleep(time_between_treatment)\n",
    "    tweets_df = spark.read.format(\"mongo\").option(\"uri\", MONGODB_ATLAS_URI + \"development.tweets\").load()\n",
    "    df = tweets_df.withColumn('crypto_array', clean_crypto_array(\"cryptos\")).drop(\"cryptos\")\n",
    "    for crypto in CURRENCIES:\n",
    "        generate_result(df.where(array_contains(df['crypto_array'], crypto)), db, crypto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5f0d78b971cebfd0fc5d9c1218d70482ef2084c4205fa6cde58f629ef512bd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
